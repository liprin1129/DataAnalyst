{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Dimensional NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2328\n",
      "[[2328 2539]\n",
      " [6461 2691]]\n",
      "[1478 3877 3674 2328 2539]\n"
     ]
    }
   ],
   "source": [
    "# Accessing elements\n",
    "if True:\n",
    "    print(ridership[1, 3])\n",
    "    print(ridership[1:3, 3:5])\n",
    "    print(ridership[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1478 3877 3676 2333 2539]\n",
      "[   0 5355 5701 4952 6410 5509  324    2 5223 5385]\n"
     ]
    }
   ],
   "source": [
    "# Vectorized operations on rows or columns\n",
    "if True:\n",
    "    print(ridership[0, :] + ridership[1, :])\n",
    "    print(ridership[:, 0] + ridership[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  3  4]\n",
      " [ 6  7  8]\n",
      " [10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "# Vectorized operations on entire arrays\n",
    "if True:\n",
    "    a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "    b = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "    print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2342.6\n",
      "3239.9\n"
     ]
    }
   ],
   "source": [
    "print(ridership.mean())\n",
    "print(ridership[:, ridership[0, :].argmax()].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    Hint: NumPy's argmax() function might be useful:\n",
    "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html\n",
    "    '''\n",
    "    max_station = ridership[0, :].argmax()\n",
    "    overall_mean = ridership.mean()\n",
    "    mean_for_max = ridership[:, max_station].mean()\n",
    "    \n",
    "    return (overall_mean, mean_for_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# NumPy Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "[12 15 18]\n",
      "[ 6 15 24]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# NumPy axis argument\n",
    "if True:\n",
    "    a = np.array([\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]\n",
    "    ])\n",
    "    \n",
    "    print(a.sum())\n",
    "    print(a.sum(axis=0))\n",
    "    print(a.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])\n",
    "\n",
    "\n",
    "def min_and_max_riders_per_day(ridership):\n",
    "    '''\n",
    "    Fill in this function. First, for each subway station, calculate the\n",
    "    mean ridership per day. Then, out of all the subway stations, return the\n",
    "    maximum and minimum of these values. That is, find the maximum\n",
    "    mean-ridership-per-day and the minimum mean-ridership-per-day for any\n",
    "    subway station.\n",
    "    '''\n",
    "    mean_daily = ridership.mean(axis=0)\n",
    "    max_daily_ridership = mean_daily.max()\n",
    "    min_daily_ridership = mean_daily.min()\n",
    "    \n",
    "    return (max_daily_ridership, min_daily_ridership)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Accessing Elements Of A DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R003</th>\n",
       "      <th>R004</th>\n",
       "      <th>R005</th>\n",
       "      <th>R006</th>\n",
       "      <th>R007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>05-01-11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-02-11</th>\n",
       "      <td>1478</td>\n",
       "      <td>3877</td>\n",
       "      <td>3674</td>\n",
       "      <td>2328</td>\n",
       "      <td>2539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-03-11</th>\n",
       "      <td>1613</td>\n",
       "      <td>4088</td>\n",
       "      <td>3991</td>\n",
       "      <td>6461</td>\n",
       "      <td>2691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-04-11</th>\n",
       "      <td>1560</td>\n",
       "      <td>3392</td>\n",
       "      <td>3826</td>\n",
       "      <td>4787</td>\n",
       "      <td>2613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-05-11</th>\n",
       "      <td>1608</td>\n",
       "      <td>4802</td>\n",
       "      <td>3932</td>\n",
       "      <td>4477</td>\n",
       "      <td>2705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-06-11</th>\n",
       "      <td>1576</td>\n",
       "      <td>3933</td>\n",
       "      <td>3909</td>\n",
       "      <td>4979</td>\n",
       "      <td>2685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-07-11</th>\n",
       "      <td>95</td>\n",
       "      <td>229</td>\n",
       "      <td>255</td>\n",
       "      <td>496</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-08-11</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-09-11</th>\n",
       "      <td>1438</td>\n",
       "      <td>3785</td>\n",
       "      <td>3589</td>\n",
       "      <td>4174</td>\n",
       "      <td>2215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-10-11</th>\n",
       "      <td>1342</td>\n",
       "      <td>4043</td>\n",
       "      <td>4009</td>\n",
       "      <td>4665</td>\n",
       "      <td>3033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          R003  R004  R005  R006  R007\n",
       "05-01-11     0     0     2     5     0\n",
       "05-02-11  1478  3877  3674  2328  2539\n",
       "05-03-11  1613  4088  3991  6461  2691\n",
       "05-04-11  1560  3392  3826  4787  2613\n",
       "05-05-11  1608  4802  3932  4477  2705\n",
       "05-06-11  1576  3933  3909  4979  2685\n",
       "05-07-11    95   229   255   496   201\n",
       "05-08-11     2     0     1    27     0\n",
       "05-09-11  1438  3785  3589  4174  2215\n",
       "05-10-11  1342  4043  4009  4665  3033"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership_df = pd.DataFrame(\n",
    "    data=[[   0,    0,    2,    5,    0],\n",
    "          [1478, 3877, 3674, 2328, 2539],\n",
    "          [1613, 4088, 3991, 6461, 2691],\n",
    "          [1560, 3392, 3826, 4787, 2613],\n",
    "          [1608, 4802, 3932, 4477, 2705],\n",
    "          [1576, 3933, 3909, 4979, 2685],\n",
    "          [  95,  229,  255,  496,  201],\n",
    "          [   2,    0,    1,   27,    0],\n",
    "          [1438, 3785, 3589, 4174, 2215],\n",
    "          [1342, 4043, 4009, 4665, 3033]],\n",
    "    index=['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "           '05-06-11', '05-07-11', '05-08-11', '05-09-11', '05-10-11'],\n",
    "    columns=['R003', 'R004', 'R005', 'R006', 'R007']\n",
    ")\n",
    "\n",
    "ridership_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  0  3\n",
      "1  1  4\n",
      "2  2  5\n",
      "   A  B  C\n",
      "0  0  1  2\n",
      "1  3  4  5\n"
     ]
    }
   ],
   "source": [
    "# DataFrame creation\n",
    "if True:\n",
    "    # You can create a DataFrame out of a dictionary mapping column names to values\n",
    "    df_1 = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "    print(df_1)\n",
    "\n",
    "    # You can also use a list of lists or a 2D NumPy array\n",
    "    df_2 = pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=['A', 'B', 'C'])\n",
    "    print(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R003    0\n",
      "R004    0\n",
      "R005    2\n",
      "R006    5\n",
      "R007    0\n",
      "Name: 05-01-11, dtype: int64\n",
      "R003    1608\n",
      "R004    4802\n",
      "R005    3932\n",
      "R006    4477\n",
      "R007    2705\n",
      "Name: 05-05-11, dtype: int64\n",
      "05-01-11       0\n",
      "05-02-11    1478\n",
      "05-03-11    1613\n",
      "05-04-11    1560\n",
      "05-05-11    1608\n",
      "05-06-11    1576\n",
      "05-07-11      95\n",
      "05-08-11       2\n",
      "05-09-11    1438\n",
      "05-10-11    1342\n",
      "Name: R003, dtype: int64\n",
      "2328\n"
     ]
    }
   ],
   "source": [
    "# Accessing elements\n",
    "if True:\n",
    "    print(ridership_df.iloc[0])\n",
    "    print(ridership_df.loc['05-05-11'])\n",
    "    print(ridership_df['R003'])\n",
    "    print(ridership_df.iloc[1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          R003  R004  R005  R006  R007\n",
      "05-02-11  1478  3877  3674  2328  2539\n",
      "05-03-11  1613  4088  3991  6461  2691\n",
      "05-04-11  1560  3392  3826  4787  2613\n"
     ]
    }
   ],
   "source": [
    "# Accessing multiple rows\n",
    "if True:\n",
    "    print(ridership_df.iloc[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          R003  R005\n",
      "05-01-11     0     2\n",
      "05-02-11  1478  3674\n",
      "05-03-11  1613  3991\n",
      "05-04-11  1560  3826\n",
      "05-05-11  1608  3932\n",
      "05-06-11  1576  3909\n",
      "05-07-11    95   255\n",
      "05-08-11     2     1\n",
      "05-09-11  1438  3589\n",
      "05-10-11  1342  4009\n"
     ]
    }
   ],
   "source": [
    "# Accessing multiple columns\n",
    "if True:\n",
    "    print(ridership_df[['R003', 'R005']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A     3\n",
      "B    12\n",
      "dtype: int64\n",
      "0    3\n",
      "1    5\n",
      "2    7\n",
      "dtype: int64\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Pandas axis\n",
    "if True:\n",
    "    df = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "    print(df.sum())\n",
    "    print(df.sum(axis=1))\n",
    "    print(df.values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3239.9\n"
     ]
    }
   ],
   "source": [
    "max_rider = ridership_df.iloc[0].argmax()\n",
    "print(ridership_df[max_rider].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2342.5999999999999, 3239.9)\n"
     ]
    }
   ],
   "source": [
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    This is the same as a previous exercise, but this time the\n",
    "    input is a Pandas DataFrame rather than a 2D NumPy array.\n",
    "    '''\n",
    "    max_station = ridership.iloc[0].argmax()\n",
    "    overall_mean = ridership.values.mean()\n",
    "    mean_for_max = ridership[max_station].mean()\n",
    "    \n",
    "    return (overall_mean, mean_for_max)\n",
    "\n",
    "print(mean_riders_for_max_station(ridership_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Calculating Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03564851577223041\n",
      "-0.026693348321569912\n",
      "-0.22903432340833663\n",
      "0.5858954707662182\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/Users/pure/Documents/Personal_Development/Udacity/Data_Analyst/Lessons/2. Data Analysis/Lesson 3. NumPy & Pandas for 2D data/'\n",
    "filename = file_path + 'nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "\n",
    "def correlation(x, y):\n",
    "    '''\n",
    "    Fill in this function to compute the correlation between the two\n",
    "    input variables. Each input is either a NumPy array or a Pandas\n",
    "    Series.\n",
    "    \n",
    "    correlation = average of (x in standard units) times (y in standard units)\n",
    "    \n",
    "    Remember to pass the argument \"ddof=0\" to the Pandas std() function!\n",
    "    '''\n",
    "    std_x= (x - x.mean()) / x.std(ddof=0)\n",
    "    std_y = (y - y.mean()) / y.std(ddof=0)\n",
    "    \n",
    "    return (std_x * std_y).mean()\n",
    "\n",
    "entries = subway_df['ENTRIESn_hourly']\n",
    "cum_entries = subway_df['ENTRIESn']\n",
    "rain = subway_df['meanprecipi']\n",
    "temp = subway_df['meantempi']\n",
    "\n",
    "print(correlation(entries, rain))\n",
    "print(correlation(entries, temp))\n",
    "print(correlation(rain, temp))\n",
    "\n",
    "print(correlation(entries, cum_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "x = pd.Series([1, 2, 3, 4])\n",
    "y = pd.Series([10, 11, 12, 13])\n",
    "\n",
    "print(correlation(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DataFrame Vectorized Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c\n",
      "0  11  44  77\n",
      "1  22  55  88\n",
      "2  33  66  99\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Examples of vectorized operations on DataFrames:\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding DataFrames with the column names\n",
    "if True:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]})\n",
    "    print(df1 + df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d\n",
      "0 NaN  74  47 NaN\n",
      "1 NaN  85  58 NaN\n",
      "2 NaN  96  69 NaN\n"
     ]
    }
   ],
   "source": [
    "# Adding DataFrames with overlapping column names \n",
    "if True:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'d': [10, 20, 30], 'c': [40, 50, 60], 'b': [70, 80, 90]})\n",
    "    print(df1 + df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         a     b     c\n",
      "row1   NaN   NaN   NaN\n",
      "row2  32.0  65.0  98.0\n",
      "row3  23.0  56.0  89.0\n",
      "row4   NaN   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "# Adding DataFrames with overlapping row indexes\n",
    "if True:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]},\n",
    "                       index=['row1', 'row2', 'row3'])\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]},\n",
    "                       index=['row4', 'row3', 'row2'])\n",
    "    print(df1 + df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>214.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>153.0</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENTRIESn  EXITSn\n",
       "0       NaN     NaN\n",
       "1      23.0     8.0\n",
       "2      18.0    18.0\n",
       "3      71.0    54.0\n",
       "4     170.0    44.0\n",
       "5     214.0    42.0\n",
       "6      87.0    11.0\n",
       "7      10.0     3.0\n",
       "8      36.0    89.0\n",
       "9     153.0   333.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Quiz ---\n",
    "# Cumulative entries and exits for one station for a few hours.\n",
    "entries_and_exits = pd.DataFrame({\n",
    "    'ENTRIESn': [3144312, 3144335, 3144353, 3144424, 3144594,\n",
    "                 3144808, 3144895, 3144905, 3144941, 3145094],\n",
    "    'EXITSn': [1088151, 1088159, 1088177, 1088231, 1088275,\n",
    "               1088317, 1088328, 1088331, 1088420, 1088753]\n",
    "})\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits (entries in the first column, exits in the second) and\n",
    "    return a DataFrame with hourly entries and exits (entries in the\n",
    "    first column, exits in the second).\n",
    "    '''\n",
    "    # return entries_and_exits - entries_and_exits.shift(1) \n",
    "    # or\n",
    "    return entries_and_exits.diff()\n",
    "\n",
    "get_hourly_entries_and_exits(entries_and_exits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DataFrame Applymap()\n",
    "\n",
    "_Elements_ in DataFrame can be mapped by a function using _.applymap()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a   b   c\n",
      "0  2  11   6\n",
      "1  3  21  11\n",
      "2  4  31  16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# DataFrame applymap()\n",
    "if True:\n",
    "    df = pd.DataFrame({\n",
    "        'a': [1, 2, 3],\n",
    "        'b': [10, 20, 30],\n",
    "        'c': [5, 10, 15]\n",
    "    })\n",
    "    \n",
    "    def add_one(x):\n",
    "        return x + 1\n",
    "        \n",
    "    print(df.applymap(add_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>81</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>78</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dan</th>\n",
       "      <td>75</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilio</th>\n",
       "      <td>89</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fred</th>\n",
       "      <td>70</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greta</th>\n",
       "      <td>91</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humbert</th>\n",
       "      <td>65</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivan</th>\n",
       "      <td>98</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>87</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         exam1  exam2\n",
       "Andre       43     24\n",
       "Barry       81     63\n",
       "Chris       78     56\n",
       "Dan         75     56\n",
       "Emilio      89     67\n",
       "Fred        70     51\n",
       "Greta       91     79\n",
       "Humbert     65     46\n",
       "Ivan        98     72\n",
       "James       87     60"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "grades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dan</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilio</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fred</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greta</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humbert</th>\n",
       "      <td>D</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivan</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        exam1 exam2\n",
       "Andre       F     F\n",
       "Barry       B     D\n",
       "Chris       C     F\n",
       "Dan         C     F\n",
       "Emilio      B     D\n",
       "Fred        C     F\n",
       "Greta       A     C\n",
       "Humbert     D     F\n",
       "Ivan        A     C\n",
       "James       B     D"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_grades(grades_df):\n",
    "    '''\n",
    "    Fill in this function to convert the given DataFrame of numerical\n",
    "    grades to letter grades. Return a new DataFrame with the converted\n",
    "    grade.\n",
    "    \n",
    "    The conversion rule is:\n",
    "        90-100 -> A\n",
    "        80-89  -> B\n",
    "        70-79  -> C\n",
    "        60-69  -> D\n",
    "        0-59   -> F\n",
    "    '''\n",
    "    def convert(grades):\n",
    "        if grades >= 90:\n",
    "            grades = 'A'\n",
    "        elif grades >= 80:\n",
    "            grades = 'B'\n",
    "        elif grades >= 70:\n",
    "            grades = 'C'\n",
    "        elif grades >= 60:\n",
    "            grades = 'D'\n",
    "        else:\n",
    "            grades = 'F'\n",
    "        return grades\n",
    "    \n",
    "    return grades_df.applymap(convert)\n",
    "\n",
    "convert_grades(grades_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "# DataFrame Apply() Use Case 1\n",
    "\n",
    "_Columns (or Series)_ in DataFrame can be mapped by a function using _.apply()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>81</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>78</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dan</th>\n",
       "      <td>75</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilio</th>\n",
       "      <td>89</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fred</th>\n",
       "      <td>70</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greta</th>\n",
       "      <td>91</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humbert</th>\n",
       "      <td>65</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivan</th>\n",
       "      <td>98</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>87</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         exam1  exam2\n",
       "Andre       43     24\n",
       "Barry       81     63\n",
       "Chris       78     56\n",
       "Dan         75     56\n",
       "Emilio      89     67\n",
       "Fred        70     51\n",
       "Greta       91     79\n",
       "Humbert     65     46\n",
       "Ivan        98     72\n",
       "James       87     60"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "grades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andre      F\n",
      "Barry      B\n",
      "Chris      C\n",
      "Dan        C\n",
      "Emilio     B\n",
      "Fred       C\n",
      "Greta      A\n",
      "Humbert    D\n",
      "Ivan       A\n",
      "James      B\n",
      "Name: exam1, dtype: category\n",
      "Categories (5, object): [F < D < C < B < A]\n",
      "        exam1 exam2\n",
      "Andre       F     F\n",
      "Barry       B     B\n",
      "Chris       C     C\n",
      "Dan         C     C\n",
      "Emilio      B     B\n",
      "Fred        C     C\n",
      "Greta       A     A\n",
      "Humbert     D     D\n",
      "Ivan        A     A\n",
      "James       B     B\n"
     ]
    }
   ],
   "source": [
    "# DataFrame apply()\n",
    "if True:\n",
    "    def convert_grades_curve(exam_grades):\n",
    "        # Pandas has a bult-in function that will perform this calculation\n",
    "        # This will give the bottom 0% to 10% of students the grade 'F',\n",
    "        # 10% to 20% the grade 'D', and so on. You can read more about\n",
    "        # the qcut() function here:\n",
    "        # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "        return pd.qcut(exam_grades,\n",
    "                       [0, 0.1, 0.2, 0.5, 0.8, 1],\n",
    "                       labels=['F', 'D', 'C', 'B', 'A'])\n",
    "        \n",
    "    # qcut() operates on a list, array, or Series. This is the\n",
    "    # result of running the function on a single column of the\n",
    "    # DataFrame.\n",
    "    print(convert_grades_curve(grades_df['exam1']))\n",
    "    \n",
    "    # qcut() does not work on DataFrames, but we can use apply()\n",
    "    # to call the function on each column separately\n",
    "    print(grades_df.apply(convert_grades_curve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>-2.315341</td>\n",
       "      <td>-2.304599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>0.220191</td>\n",
       "      <td>0.386400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>0.020017</td>\n",
       "      <td>-0.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dan</th>\n",
       "      <td>-0.180156</td>\n",
       "      <td>-0.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilio</th>\n",
       "      <td>0.753987</td>\n",
       "      <td>0.662400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fred</th>\n",
       "      <td>-0.513779</td>\n",
       "      <td>-0.441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greta</th>\n",
       "      <td>0.887436</td>\n",
       "      <td>1.490400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humbert</th>\n",
       "      <td>-0.847401</td>\n",
       "      <td>-0.786600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivan</th>\n",
       "      <td>1.354508</td>\n",
       "      <td>1.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>0.620538</td>\n",
       "      <td>0.179400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            exam1     exam2\n",
       "Andre   -2.315341 -2.304599\n",
       "Barry    0.220191  0.386400\n",
       "Chris    0.020017 -0.096600\n",
       "Dan     -0.180156 -0.096600\n",
       "Emilio   0.753987  0.662400\n",
       "Fred    -0.513779 -0.441600\n",
       "Greta    0.887436  1.490400\n",
       "Humbert -0.847401 -0.786600\n",
       "Ivan     1.354508  1.007400\n",
       "James    0.620538  0.179400"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    '''\n",
    "    def standardize_column(series):\n",
    "        standard_deviation = series.std(ddof=0)\n",
    "        mean = series.mean()\n",
    "        return (series - mean) / standard_deviation\n",
    "\n",
    "    return df.apply(standardize_column)\n",
    "\n",
    "standardize(grades_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DataFrame Apply() Use Case 2\n",
    "\n",
    "Instead of taking one column and returning a new column, the function $f$ can take in one column and return just a single value, where each column of the data frame has been reduced to a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 3, 1, 2],\n",
    "    'b': [20, 10, 40, 50, 30],\n",
    "    'c': [25, 20, 5, 15, 10]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     3.0\n",
      "b    30.0\n",
      "c    15.0\n",
      "dtype: float64\n",
      "a     5\n",
      "b    50\n",
      "c    25\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# DataFrame apply() - use case 2\n",
    "if True:\n",
    "    print(df.apply(np.mean))\n",
    "    print(df.apply(np.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4\n",
      "1    5\n",
      "2    3\n",
      "3    1\n",
      "4    2\n",
      "Name: a, dtype: int64\n",
      "0    20\n",
      "1    10\n",
      "2    40\n",
      "3    50\n",
      "4    30\n",
      "Name: b, dtype: int64\n",
      "0    25\n",
      "1    20\n",
      "2     5\n",
      "3    15\n",
      "4    10\n",
      "Name: c, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a     4\n",
       "b    40\n",
       "c    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def second_largest(df):\n",
    "    '''\n",
    "    Fill in this function to return the second-largest value of each \n",
    "    column of the input DataFrame.\n",
    "    '''\n",
    "    def second_largest_in_column(series):\n",
    "        sorted_series = series.sort_values(ascending=False)\n",
    "        print(series)\n",
    "        return sorted_series.iloc[1]\n",
    "    return df.apply(second_largest_in_column)\n",
    "\n",
    "second_largest(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Adding A DataFrame To A Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1    2    3\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "    0   1    2    3\n",
      "0  11  52   93  134\n",
      "1  21  62  103  144\n",
      "2  31  72  113  154\n",
      "3  41  82  123  164\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding a Series to a square DataFrame\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print(df)\n",
    "    print('') # Create a blank line between outputs\n",
    "    print(df + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3\n",
      "0  10  20  30  40\n",
      "\n",
      "    0   1   2   3\n",
      "0  11  22  33  44\n"
     ]
    }
   ],
   "source": [
    "# Adding a Series to a one-row DataFrame \n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10], 1: [20], 2: [30], 3: [40]})\n",
    "    \n",
    "    print(df)\n",
    "    print('') # Create a blank line between outputs\n",
    "    print(df + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0\n",
      "0  10\n",
      "1  20\n",
      "2  30\n",
      "3  40\n",
      "\n",
      "    0   1   2   3\n",
      "0  11 NaN NaN NaN\n",
      "1  21 NaN NaN NaN\n",
      "2  31 NaN NaN NaN\n",
      "3  41 NaN NaN NaN\n"
     ]
    }
   ],
   "source": [
    "# Adding a Series to a one-column DataFrame\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10, 20, 30, 40]})\n",
    "    \n",
    "    print(df)\n",
    "    print('') # Create a blank line between outputs\n",
    "    print(df + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0\n",
      "0  10\n",
      "1  20\n",
      "2  30\n",
      "3  40\n",
      "\n",
      "    0   1   2   3\n",
      "0  11 NaN NaN NaN\n",
      "1  21 NaN NaN NaN\n",
      "2  31 NaN NaN NaN\n",
      "3  41 NaN NaN NaN\n",
      "\n",
      "    0\n",
      "0  11\n",
      "1  22\n",
      "2  33\n",
      "3  44\n"
     ]
    }
   ],
   "source": [
    "# Adding a Series to a one-column DataFrame by index or column\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10, 20, 30, 40]})\n",
    "    \n",
    "    print(df)\n",
    "    print('') # Create a blank line between outputs\n",
    "    print(df.add(s, axis='columns'))\n",
    "    print('') # Create a blank line between outputs\n",
    "    print(df.add(s, axis='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b    c    d\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "    a   b    c    d\n",
      "0  11  52   93  134\n",
      "1  21  62  103  144\n",
      "2  31  72  113  154\n",
      "3  41  82  123  164\n"
     ]
    }
   ],
   "source": [
    "# Adding when DataFrame column names match Series index\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print(df)\n",
    "    print('') # Create a blank line between outputs\n",
    "    print(df + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b    c    d\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "    a     b      c      d   e\n",
      "0 NaN  51.0   92.0  133.0 NaN\n",
      "1 NaN  61.0  102.0  143.0 NaN\n",
      "2 NaN  71.0  112.0  153.0 NaN\n",
      "3 NaN  81.0  122.0  163.0 NaN\n"
     ]
    }
   ],
   "source": [
    "# Adding when DataFrame column names match Series index\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4], index=['b', 'c', 'd', 'e'])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print(df)\n",
    "    print('') # Create a blank line between outputs\n",
    "    print(df + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b    c    d\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "    a   b   c   d   0   1   2   3\n",
      "0 NaN NaN NaN NaN NaN NaN NaN NaN\n",
      "1 NaN NaN NaN NaN NaN NaN NaN NaN\n",
      "2 NaN NaN NaN NaN NaN NaN NaN NaN\n",
      "3 NaN NaN NaN NaN NaN NaN NaN NaN\n"
     ]
    }
   ],
   "source": [
    "# Adding when DataFrame column names don't match Series index\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print(df)\n",
    "    print('') # Create a blank line between outputs\n",
    "    print(df + s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Standardizing Each Column Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1    2    3\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "    0   1    2    3\n",
      "0  11  52   93  134\n",
      "1  21  62  103  144\n",
      "2  31  72  113  154\n",
      "3  41  82  123  164\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Adding using +\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print(df)\n",
    "    print('') # Create a blank line between outputs\n",
    "    print(df + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1    2    3\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "    0   1    2    3\n",
      "0  11  51   91  131\n",
      "1  22  62  102  142\n",
      "2  33  73  113  153\n",
      "3  44  84  124  164\n"
     ]
    }
   ],
   "source": [
    "# Adding with axis='index'\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print(df)\n",
    "    print('')\n",
    "    print(df.add(s, axis='index'))\n",
    "    # The functions sub(), mul(), and div() work similarly to add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1    2    3\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "    0   1    2    3\n",
      "0  11  52   93  134\n",
      "1  21  62  103  144\n",
      "2  31  72  113  154\n",
      "3  41  82  123  164\n"
     ]
    }
   ],
   "source": [
    "# Adding with axis='columns'\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print(df)\n",
    "    print('')\n",
    "    print(df.add(s, axis='columns'))\n",
    "    # The functions sub(), mul(), and div() work similarly to add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    \n",
    "    This time, try to use vectorized operations instead of apply().\n",
    "    You should get the same results as you did before.\n",
    "    '''\n",
    "    return (df - df.mean()) / df.std(ddof=0)\n",
    "\n",
    "def standardize_rows(df):\n",
    "    '''\n",
    "    Optional: Fill in this function to standardize each row of the given\n",
    "    DataFrame. Again, try not to use apply().\n",
    "    \n",
    "    This one is more challenging than standardizing each column!\n",
    "    '''\n",
    "    mean_diffs = df.sub(df.mean(axis='columns'), axis='index')\n",
    "    return mean_diffs.div(df.std(ddof=0, axis='columns'), axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         exam1  exam2\n",
      "Andre      1.0   -1.0\n",
      "Barry      1.0   -1.0\n",
      "Chris      1.0   -1.0\n",
      "Dan        1.0   -1.0\n",
      "Emilio     1.0   -1.0\n",
      "Fred       1.0   -1.0\n",
      "Greta      1.0   -1.0\n",
      "Humbert    1.0   -1.0\n",
      "Ivan       1.0   -1.0\n",
      "James      1.0   -1.0\n"
     ]
    }
   ],
   "source": [
    "print(standardize_rows(grades_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pandas Groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  above_three   even  value\n",
      "a       False  False      1\n",
      "b       False  False      3\n",
      "c       False   True      2\n",
      "d        True   True      4\n",
      "e       False  False      1\n",
      "f        True   True      6\n",
      "g        True   True      4\n"
     ]
    }
   ],
   "source": [
    "# Examine DataFrame\n",
    "if True:\n",
    "    print(example_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{False: Index(['a', 'b', 'e'], dtype='object'), True: Index(['c', 'd', 'f', 'g'], dtype='object')}\n"
     ]
    }
   ],
   "source": [
    "# Examine groups\n",
    "if True:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    # The groups attribute is a dictionary mapping keys to lists of row indexes\n",
    "    print(grouped_data.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(True, False): Index(['c'], dtype='object'), (False, False): Index(['a', 'b', 'e'], dtype='object'), (True, True): Index(['d', 'f', 'g'], dtype='object')}\n"
     ]
    }
   ],
   "source": [
    "# Group by multiple columns\n",
    "if True:\n",
    "    grouped_data = example_df.groupby(['even', 'above_three'])\n",
    "    print(grouped_data.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       above_three  value\n",
      "even                     \n",
      "False          0.0      5\n",
      "True           3.0     16\n"
     ]
    }
   ],
   "source": [
    "# Get sum of each group\n",
    "if True:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print(grouped_data.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even\n",
      "False     5\n",
      "True     16\n",
      "Name: value, dtype: int64\n",
      "\n",
      "\n",
      "even\n",
      "False     5\n",
      "True     16\n",
      "Name: value, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Limit columns in result\n",
    "if True:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    \n",
    "    # You can take one or more columns from the result DataFrame\n",
    "    print(grouped_data.sum()['value'])\n",
    "    \n",
    "    print('\\n') # Blank line to separate results\n",
    "    \n",
    "    # You can also take a subset of columns from the grouped data before \n",
    "    # collapsing to a DataFrame. In this case, the result is the same.\n",
    "    print(grouped_data['value'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UNIT     DATEn     TIMEn  ENTRIESn   EXITSn  ENTRIESn_hourly  \\\n",
      "0  R003  05-01-11  00:00:00   4388333  2911002              0.0   \n",
      "1  R003  05-01-11  04:00:00   4388333  2911002              0.0   \n",
      "2  R003  05-01-11  12:00:00   4388333  2911002              0.0   \n",
      "3  R003  05-01-11  16:00:00   4388333  2911002              0.0   \n",
      "4  R003  05-01-11  20:00:00   4388333  2911002              0.0   \n",
      "\n",
      "   EXITSn_hourly             datetime  hour  day_week     ...       pressurei  \\\n",
      "0            0.0  2011-05-01 00:00:00     0         6     ...           30.22   \n",
      "1            0.0  2011-05-01 04:00:00     4         6     ...           30.25   \n",
      "2            0.0  2011-05-01 12:00:00    12         6     ...           30.28   \n",
      "3            0.0  2011-05-01 16:00:00    16         6     ...           30.26   \n",
      "4            0.0  2011-05-01 20:00:00    20         6     ...           30.28   \n",
      "\n",
      "  rain  tempi  wspdi meanprecipi  meanpressurei  meantempi  meanwspdi  \\\n",
      "0    0   55.9    3.5         0.0         30.258      55.98       7.86   \n",
      "1    0   52.0    3.5         0.0         30.258      55.98       7.86   \n",
      "2    0   62.1    6.9         0.0         30.258      55.98       7.86   \n",
      "3    0   57.9   15.0         0.0         30.258      55.98       7.86   \n",
      "4    0   52.0   10.4         0.0         30.258      55.98       7.86   \n",
      "\n",
      "   weather_lat  weather_lon  \n",
      "0    40.700348   -73.887177  \n",
      "1    40.700348   -73.887177  \n",
      "2    40.700348   -73.887177  \n",
      "3    40.700348   -73.887177  \n",
      "4    40.700348   -73.887177  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1050708d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEFCAYAAAAPCDf9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJI4o9EVE4sj/B4MT/e4OxUFLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107877278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = 'nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "### Write code here to group the subway data by a variable of your choice, then\n",
    "### either print out the mean ridership within each group or create a plot.\n",
    "\n",
    "print(subway_df.head())\n",
    "\n",
    "ridership_by_day = subway_df.groupby('day_week').mean()['ENTRIESn_hourly']\n",
    "\n",
    "%pylab inline\n",
    "import seaborn as sns\n",
    "\n",
    "ridership_by_day.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Calculating Hourly Entries and Exits\n",
    "\n",
    "In the quiz where you calculated hourly entries and exits, you did so for a single set of cumulative entries. However, in the original data, there was a separate set of numbers for each station.\n",
    "\n",
    "Thus, to correctly calculate the hourly entries and exits, it was necessary to group by station and day, then calculate the hourly entries and exits within each day.\n",
    "\n",
    "Write a function to do that. You should use the __apply()__ function to call the function you wrote previously. You should also make sure you restrict your grouped data to just the entries and exits columns, since your function may cause an error if it is called on non-numerical data types.\n",
    "\n",
    "If you would like to learn more about using __groupby()__ in Pandas, [this page](http://pandas.pydata.org/pandas-docs/stable/groupby.html) contains more details.\n",
    "\n",
    "Note: You will not be able to reproduce the __ENTRIESn_hourly__ and __EXITSn_hourly__ columns in the full dataset using this method. When creating the dataset, we did extra processing to remove erroneous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a   -0.577350\n",
      "b    1.154701\n",
      "c   -1.224745\n",
      "d    0.000000\n",
      "e   -0.577350\n",
      "f    1.224745\n",
      "g    0.000000\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Standardize each group\n",
    "if True:\n",
    "    def standardize(xs):\n",
    "        return (xs - xs.mean()) / xs.std()\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print(grouped_data['value'].apply(standardize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even\n",
      "False    1\n",
      "True     4\n",
      "Name: value, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find second largest value in each group\n",
    "if True:\n",
    "    def second_largest(xs):\n",
    "        sorted_xs = xs.sort_values(inplace=False, ascending=False)\n",
    "        return sorted_xs.iloc[1]\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print(grouped_data['value'].apply(second_largest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Quiz ---\n",
    "# DataFrame with cumulative entries and exits for multiple stations\n",
    "ridership_df = pd.DataFrame({\n",
    "    'UNIT': ['R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051'],\n",
    "    'TIMEn': ['00:00:00', '02:00:00', '04:00:00', '06:00:00', '08:00:00', '10:00:00', '12:00:00', '14:00:00', '16:00:00'],\n",
    "    'ENTRIESn': [3144312, 8936644, 3144335, 8936658, 3144353, 8936687, 3144424, 8936819, 3144594],\n",
    "    'EXITSn': [1088151, 13755385,  1088159, 13755393,  1088177, 13755598, 1088231, 13756191,  1088275]\n",
    "})\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits and return a DataFrame with hourly entries and exits.\n",
    "    The hourly entries and exits should be calculated separately for\n",
    "    each station (the 'UNIT' column).\n",
    "    \n",
    "    Hint: Use the `get_hourly_entries_and_exits()` function you wrote\n",
    "    in a previous quiz, DataFrame Vectorized Operations, and the `.apply()`\n",
    "    function, to help solve this problem.\n",
    "    '''\n",
    "    def hourly_for_group(entries_and_exits):\n",
    "        return entries_and_exits.diff()\n",
    "        # return entries_and_exits - entries_and_exits.shift(1)\n",
    "    return entries_and_exits.apply(hourly_for_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.0</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>71.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>132.0</td>\n",
       "      <td>593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>170.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENTRIESn  EXITSn\n",
       "0       NaN     NaN\n",
       "1       NaN     NaN\n",
       "2      23.0     8.0\n",
       "3      14.0     8.0\n",
       "4      18.0    18.0\n",
       "5      29.0   205.0\n",
       "6      71.0    54.0\n",
       "7     132.0   593.0\n",
       "8     170.0    44.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data = ridership_df.groupby('UNIT')\n",
    "get_hourly_entries_and_exits(grouped_data['ENTRIESn', 'EXITSn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Combining Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "subway_df = pd.DataFrame({\n",
    "    'UNIT': ['R003', 'R003', 'R003', 'R003', 'R003', 'R004', 'R004', 'R004',\n",
    "             'R004', 'R004'],\n",
    "    'DATEn': ['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "              '05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'ENTRIESn': [ 4388333,  4388348,  4389885,  4391507,  4393043, 14656120,\n",
    "                 14656174, 14660126, 14664247, 14668301],\n",
    "    'EXITSn': [ 2911002,  2911036,  2912127,  2913223,  2914284, 14451774,\n",
    "               14451851, 14454734, 14457780, 14460818],\n",
    "    'latitude': [ 40.689945,  40.689945,  40.689945,  40.689945,  40.689945,\n",
    "                  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.872564, -73.872564, -73.872564, -73.872564,\n",
    "                  -73.867135, -73.867135, -73.867135, -73.867135, -73.867135]\n",
    "})\n",
    "\n",
    "weather_df = pd.DataFrame({\n",
    "    'DATEn': ['05-01-11', '05-01-11', '05-02-11', '05-02-11', '05-03-11',\n",
    "              '05-03-11', '05-04-11', '05-04-11', '05-05-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'latitude': [ 40.689945,  40.69132 ,  40.689945,  40.69132 ,  40.689945,\n",
    "                  40.69132 ,  40.689945,  40.69132 ,  40.689945,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.867135, -73.872564, -73.867135, -73.872564,\n",
    "                  -73.867135, -73.872564, -73.867135, -73.872564, -73.867135],\n",
    "    'pressurei': [ 30.24,  30.24,  30.32,  30.32,  30.14,  30.14,  29.98,  29.98,\n",
    "                   30.01,  30.01],\n",
    "    'fog': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'rain': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'tempi': [ 52. ,  52. ,  48.9,  48.9,  54. ,  54. ,  57.2,  57.2,  48.9,  48.9],\n",
    "    'wspdi': [  8.1,   8.1,   6.9,   6.9,   3.5,   3.5,  15. ,  15. ,  15. ,  15. ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_dfs(subway_df, weather_df):\n",
    "    '''\n",
    "    Fill in this function to take 2 DataFrames, one with subway data and one with weather data,\n",
    "    and return a single dataframe with one row for each date, hour, and location. Only include\n",
    "    times and locations that have both subway data and weather data available.\n",
    "    '''\n",
    "    return weather_df.merge(subway_df, on=['DATEn', 'hour', 'latitude', 'longitude'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATEn</th>\n",
       "      <th>fog</th>\n",
       "      <th>hour</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>pressurei</th>\n",
       "      <th>rain</th>\n",
       "      <th>tempi</th>\n",
       "      <th>wspdi</th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "      <th>UNIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>30.24</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>R003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>30.24</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>14656120</td>\n",
       "      <td>14451774</td>\n",
       "      <td>R004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-02-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>30.32</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4388348</td>\n",
       "      <td>2911036</td>\n",
       "      <td>R003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05-02-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>30.32</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>14656174</td>\n",
       "      <td>14451851</td>\n",
       "      <td>R004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-03-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>30.14</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4389885</td>\n",
       "      <td>2912127</td>\n",
       "      <td>R003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>05-03-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>30.14</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>14660126</td>\n",
       "      <td>14454734</td>\n",
       "      <td>R004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>05-04-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>29.98</td>\n",
       "      <td>0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4391507</td>\n",
       "      <td>2913223</td>\n",
       "      <td>R003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>05-04-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>29.98</td>\n",
       "      <td>0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14664247</td>\n",
       "      <td>14457780</td>\n",
       "      <td>R004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>05-05-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>30.01</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4393043</td>\n",
       "      <td>2914284</td>\n",
       "      <td>R003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>05-05-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>30.01</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14668301</td>\n",
       "      <td>14460818</td>\n",
       "      <td>R004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DATEn  fog  hour   latitude  longitude  pressurei  rain  tempi  wspdi  \\\n",
       "0  05-01-11    0     0  40.689945 -73.872564      30.24     0   52.0    8.1   \n",
       "1  05-01-11    0     0  40.691320 -73.867135      30.24     0   52.0    8.1   \n",
       "2  05-02-11    0     0  40.689945 -73.872564      30.32     0   48.9    6.9   \n",
       "3  05-02-11    0     0  40.691320 -73.867135      30.32     0   48.9    6.9   \n",
       "4  05-03-11    0     0  40.689945 -73.872564      30.14     0   54.0    3.5   \n",
       "5  05-03-11    0     0  40.691320 -73.867135      30.14     0   54.0    3.5   \n",
       "6  05-04-11    0     0  40.689945 -73.872564      29.98     0   57.2   15.0   \n",
       "7  05-04-11    0     0  40.691320 -73.867135      29.98     0   57.2   15.0   \n",
       "8  05-05-11    0     0  40.689945 -73.872564      30.01     0   48.9   15.0   \n",
       "9  05-05-11    0     0  40.691320 -73.867135      30.01     0   48.9   15.0   \n",
       "\n",
       "   ENTRIESn    EXITSn  UNIT  \n",
       "0   4388333   2911002  R003  \n",
       "1  14656120  14451774  R004  \n",
       "2   4388348   2911036  R003  \n",
       "3  14656174  14451851  R004  \n",
       "4   4389885   2912127  R003  \n",
       "5  14660126  14454734  R004  \n",
       "6   4391507   2913223  R003  \n",
       "7  14664247  14457780  R004  \n",
       "8   4393043   2914284  R003  \n",
       "9  14668301  14460818  R004  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_dfs(subway_df, weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If entry names weren't match together in both tables, we can use __left_on, right_on__ argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATEn</th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>hour</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>fog</th>\n",
       "      <th>pressurei</th>\n",
       "      <th>rain</th>\n",
       "      <th>tempi</th>\n",
       "      <th>wspdi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05-01-11</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>30.24</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-02-11</td>\n",
       "      <td>4388348</td>\n",
       "      <td>2911036</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>05-02-11</td>\n",
       "      <td>0</td>\n",
       "      <td>30.32</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-03-11</td>\n",
       "      <td>4389885</td>\n",
       "      <td>2912127</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>05-03-11</td>\n",
       "      <td>0</td>\n",
       "      <td>30.14</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05-04-11</td>\n",
       "      <td>4391507</td>\n",
       "      <td>2913223</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>05-04-11</td>\n",
       "      <td>0</td>\n",
       "      <td>29.98</td>\n",
       "      <td>0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-05-11</td>\n",
       "      <td>4393043</td>\n",
       "      <td>2914284</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>05-05-11</td>\n",
       "      <td>0</td>\n",
       "      <td>30.01</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>05-01-11</td>\n",
       "      <td>14656120</td>\n",
       "      <td>14451774</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>30.24</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>05-02-11</td>\n",
       "      <td>14656174</td>\n",
       "      <td>14451851</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>05-02-11</td>\n",
       "      <td>0</td>\n",
       "      <td>30.32</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>05-03-11</td>\n",
       "      <td>14660126</td>\n",
       "      <td>14454734</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>05-03-11</td>\n",
       "      <td>0</td>\n",
       "      <td>30.14</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>05-04-11</td>\n",
       "      <td>14664247</td>\n",
       "      <td>14457780</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>05-04-11</td>\n",
       "      <td>0</td>\n",
       "      <td>29.98</td>\n",
       "      <td>0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>05-05-11</td>\n",
       "      <td>14668301</td>\n",
       "      <td>14460818</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>05-05-11</td>\n",
       "      <td>0</td>\n",
       "      <td>30.01</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DATEn  ENTRIESn    EXITSn  UNIT  hour   latitude  longitude      date  \\\n",
       "0  05-01-11   4388333   2911002  R003     0  40.689945 -73.872564  05-01-11   \n",
       "1  05-02-11   4388348   2911036  R003     0  40.689945 -73.872564  05-02-11   \n",
       "2  05-03-11   4389885   2912127  R003     0  40.689945 -73.872564  05-03-11   \n",
       "3  05-04-11   4391507   2913223  R003     0  40.689945 -73.872564  05-04-11   \n",
       "4  05-05-11   4393043   2914284  R003     0  40.689945 -73.872564  05-05-11   \n",
       "5  05-01-11  14656120  14451774  R004     0  40.691320 -73.867135  05-01-11   \n",
       "6  05-02-11  14656174  14451851  R004     0  40.691320 -73.867135  05-02-11   \n",
       "7  05-03-11  14660126  14454734  R004     0  40.691320 -73.867135  05-03-11   \n",
       "8  05-04-11  14664247  14457780  R004     0  40.691320 -73.867135  05-04-11   \n",
       "9  05-05-11  14668301  14460818  R004     0  40.691320 -73.867135  05-05-11   \n",
       "\n",
       "   fog  pressurei  rain  tempi  wspdi  \n",
       "0    0      30.24     0   52.0    8.1  \n",
       "1    0      30.32     0   48.9    6.9  \n",
       "2    0      30.14     0   54.0    3.5  \n",
       "3    0      29.98     0   57.2   15.0  \n",
       "4    0      30.01     0   48.9   15.0  \n",
       "5    0      30.24     0   52.0    8.1  \n",
       "6    0      30.32     0   48.9    6.9  \n",
       "7    0      30.14     0   54.0    3.5  \n",
       "8    0      29.98     0   57.2   15.0  \n",
       "9    0      30.01     0   48.9   15.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "subway_df = pd.DataFrame({\n",
    "    'UNIT': ['R003', 'R003', 'R003', 'R003', 'R003', 'R004', 'R004', 'R004',\n",
    "             'R004', 'R004'],\n",
    "    'DATEn': ['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "              '05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'ENTRIESn': [ 4388333,  4388348,  4389885,  4391507,  4393043, 14656120,\n",
    "                 14656174, 14660126, 14664247, 14668301],\n",
    "    'EXITSn': [ 2911002,  2911036,  2912127,  2913223,  2914284, 14451774,\n",
    "               14451851, 14454734, 14457780, 14460818],\n",
    "    'latitude': [ 40.689945,  40.689945,  40.689945,  40.689945,  40.689945,\n",
    "                  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.872564, -73.872564, -73.872564, -73.872564,\n",
    "                  -73.867135, -73.867135, -73.867135, -73.867135, -73.867135]\n",
    "})\n",
    "\n",
    "weather_df = pd.DataFrame({\n",
    "    'date': ['05-01-11', '05-01-11', '05-02-11', '05-02-11', '05-03-11',\n",
    "              '05-03-11', '05-04-11', '05-04-11', '05-05-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'latitude': [ 40.689945,  40.69132 ,  40.689945,  40.69132 ,  40.689945,\n",
    "                  40.69132 ,  40.689945,  40.69132 ,  40.689945,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.867135, -73.872564, -73.867135, -73.872564,\n",
    "                  -73.867135, -73.872564, -73.867135, -73.872564, -73.867135],\n",
    "    'pressurei': [ 30.24,  30.24,  30.32,  30.32,  30.14,  30.14,  29.98,  29.98,\n",
    "                   30.01,  30.01],\n",
    "    'fog': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'rain': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'tempi': [ 52. ,  52. ,  48.9,  48.9,  54. ,  54. ,  57.2,  57.2,  48.9,  48.9],\n",
    "    'wspdi': [  8.1,   8.1,   6.9,   6.9,   3.5,   3.5,  15. ,  15. ,  15. ,  15. ]\n",
    "})\n",
    "\n",
    "def combine_dfs(subway_df, weather_df):\n",
    "    '''\n",
    "    Fill in this function to take 2 DataFrames, one with subway data and one with weather data,\n",
    "    and return a single dataframe with one row for each date, hour, and location. Only include\n",
    "    times and locations that have both subway data and weather data available.\n",
    "    '''\n",
    "    return subway_df.merge(weather_df,\n",
    "                            left_on=['DATEn', 'hour', 'latitude', 'longitude'], \n",
    "                            right_on=['date', 'hour', 'latitude', 'longitude'],\n",
    "                            how='inner')\n",
    "\n",
    "combine_dfs(subway_df, weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Plotting with DataFrames\n",
    "\n",
    "Just like Pandas Series, DataFrames also have a plot() method. If __*df*__ is a DataFrame, then __*df.plot()*__ will produce a line plot with a different colored line for each variable in the DataFrame. This can be a convenient way to get a quick look at your data, especially for small DataFrames, but for more complicated plots you will usually want to use matplotlib directly.\n",
    "\n",
    "In the following quiz, create a plot of your choice showing something interesting about the New York subway data. For example, you might create:\n",
    "\n",
    "- Histograms of subway ridership on both days with rain and days without rain\n",
    "- A scatterplot of subway stations with latitude and longitude as the x and y axes and ridership as the bubble size\n",
    "    - If you choose this option, you may wish to use the __*as_index=False*__ argument to groupby(). There is example code in the following quiz.\n",
    "- A scatterplot with subway ridership on one axis and precipitation or temperature on the other\n",
    "\n",
    "If you're not sure how to make the plot you want, try searching on Google or take a look at the [matplotlib documentation](http://matplotlib.org/api/pyplot_api.html). Once you've created a plot you're happy with, share what you've found on the forums!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>above_three</th>\n",
       "      <th>even</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  above_three   even  value\n",
       "a       False  False      1\n",
       "b       False  False      3\n",
       "c       False   True      2\n",
       "d        True   True      4\n",
       "e       False  False      1\n",
       "f        True   True      6\n",
       "g        True   True      4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      above_three  value\n",
      "even                    \n",
      "False       False      1\n",
      "True        False      2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'even'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'even'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-e5e6ce79a40a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfirst_even\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'even'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_even\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_even\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'even'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Causes an error. 'even' is no longer a column in the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3543\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3544\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'even'"
     ]
    }
   ],
   "source": [
    "# groupby() without as_index\n",
    "if True:\n",
    "    first_even = example_df.groupby('even').first()\n",
    "    print(first_even)\n",
    "    print(first_even['even']) # Causes an error. 'even' is no longer a column in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    even above_three  value\n",
      "0  False       False      1\n",
      "1   True       False      2\n",
      "0    False\n",
      "1     True\n",
      "Name: even, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# groupby() with as_index=False\n",
    "if True:\n",
    "    first_even = example_df.groupby('even', as_index=False).first()\n",
    "    print(first_even)\n",
    "    print(first_even['even']) # Now 'even' is still a column in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>DATEn</th>\n",
       "      <th>TIMEn</th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "      <th>ENTRIESn_hourly</th>\n",
       "      <th>EXITSn_hourly</th>\n",
       "      <th>datetime</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_week</th>\n",
       "      <th>...</th>\n",
       "      <th>pressurei</th>\n",
       "      <th>rain</th>\n",
       "      <th>tempi</th>\n",
       "      <th>wspdi</th>\n",
       "      <th>meanprecipi</th>\n",
       "      <th>meanpressurei</th>\n",
       "      <th>meantempi</th>\n",
       "      <th>meanwspdi</th>\n",
       "      <th>weather_lat</th>\n",
       "      <th>weather_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-05-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.22</td>\n",
       "      <td>0</td>\n",
       "      <td>55.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-05-01 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.25</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-05-01 12:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.28</td>\n",
       "      <td>0</td>\n",
       "      <td>62.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-05-01 16:00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.26</td>\n",
       "      <td>0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-05-01 20:00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.28</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNIT     DATEn     TIMEn  ENTRIESn   EXITSn  ENTRIESn_hourly  \\\n",
       "0  R003  05-01-11  00:00:00   4388333  2911002              0.0   \n",
       "1  R003  05-01-11  04:00:00   4388333  2911002              0.0   \n",
       "2  R003  05-01-11  12:00:00   4388333  2911002              0.0   \n",
       "3  R003  05-01-11  16:00:00   4388333  2911002              0.0   \n",
       "4  R003  05-01-11  20:00:00   4388333  2911002              0.0   \n",
       "\n",
       "   EXITSn_hourly             datetime  hour  day_week     ...       pressurei  \\\n",
       "0            0.0  2011-05-01 00:00:00     0         6     ...           30.22   \n",
       "1            0.0  2011-05-01 04:00:00     4         6     ...           30.25   \n",
       "2            0.0  2011-05-01 12:00:00    12         6     ...           30.28   \n",
       "3            0.0  2011-05-01 16:00:00    16         6     ...           30.26   \n",
       "4            0.0  2011-05-01 20:00:00    20         6     ...           30.28   \n",
       "\n",
       "  rain  tempi  wspdi meanprecipi  meanpressurei  meantempi  meanwspdi  \\\n",
       "0    0   55.9    3.5         0.0         30.258      55.98       7.86   \n",
       "1    0   52.0    3.5         0.0         30.258      55.98       7.86   \n",
       "2    0   62.1    6.9         0.0         30.258      55.98       7.86   \n",
       "3    0   57.9   15.0         0.0         30.258      55.98       7.86   \n",
       "4    0   52.0   10.4         0.0         30.258      55.98       7.86   \n",
       "\n",
       "   weather_lat  weather_lon  \n",
       "0    40.700348   -73.887177  \n",
       "1    40.700348   -73.887177  \n",
       "2    40.700348   -73.887177  \n",
       "3    40.700348   -73.887177  \n",
       "4    40.700348   -73.887177  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "subway_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'latitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'latitude'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-3980455ab99c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this is an example occuring error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdate_by_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubway_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latitude'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdate_by_location\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3543\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3544\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'latitude'"
     ]
    }
   ],
   "source": [
    "# this is an example occuring error.\n",
    "date_by_location = subway_df.groupby(['latitude', 'longitude']).mean()\n",
    "date_by_location.head()['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    40.576152\n",
       "1    40.576298\n",
       "2    40.577961\n",
       "3    40.589547\n",
       "4    40.590867\n",
       "Name: latitude, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a plot of your choice here showing something interesting about the subway data.\n",
    "## Matplotlib documentation here: http://matplotlib.org/api/pyplot_api.html\n",
    "## Once you've got something you're happy with, share it on the forums!\n",
    "date_by_location = subway_df.groupby(['latitude', 'longitude'], as_index=False).mean()\n",
    "date_by_location.head()['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_entries = date_by_location['ENTRIESn_hourly'] / date_by_location['ENTRIESn_hourly'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10fab55f8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD3CAYAAADogqi4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f83aa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.scatter(date_by_location['latitude'], date_by_location['longitude'], \n",
    "            s=scaled_entries)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
